<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>first webgpu demo</title>
  </head>
  <body>
    <h1>渲染管线基本demo</h1>
    <canvas id="gpuCanvas" width="800" height="600"></canvas>
    <script>
      async function main() {
        if (!navigator.gpu) {
          console.error("WebGPU is not supported in your browser");
          return;
        }
        const adapter = await navigator.gpu.requestAdapter();
        if (!adapter) {
          console.error("Failed to get GPU adapter");
        }
        const device = await adapter.requestDevice();
        const shaders = `
        struct VertexOut{
            @builtin(position) Position: vec4f,
            @location(0) color: vec4f
            }
        
        @vertex
        fn vertexMain(
            @location(0) position:vec4f,
            @location(1) color:vec4f
        )->VertexOut{
            var output:VertexOut;
            output.Position = position;
            output.color = color;
            return output;
        }

        @fragment
        fn fragmentMain(fragData:VertexOut)->@location(0) vec4f{
            return fragData.color;
        }
        `;
        const shaderModule = device.createShaderModule({
          code: shaders,
        }); //将WGSL格式的着色器代码编译为GPU可用的着色器模块

        const canvas = document.querySelector("#gpuCanvas");
        const context = canvas.getContext("webgpu");

        context.configure({
          device,
          format: navigator.gpu.getPreferredCanvasFormat(),
          alphaMode: "premultiplied",
        });

        const vertices = new Float32Array([
          0.0, 0.6, 0, 1, 1, 0, 0, 1, -0.5, -0.6, 0, 1, 0, 1, 0, 1, 0.5, -0.6,
          0, 1, 0, 0, 1, 1,
        ]);

        //创建GPU缓冲区存储顶点数据，并将数据从CPU内存复制到GPU

        const vertexBuffer = device.createBuffer({
          size: vertices.byteLength,
          usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
        });

        device.queue.writeBuffer(vertexBuffer, 0, vertices, 0, vertices.length);

        //指定顶点数据的内存布局
        const vertexBuffers = [
          {
            attributes: [
              {
                shaderLocation: 0,
                offset: 0,
                format: "float32x4",
              },
              {
                shaderLocation: 1,
                offset: 16,
                format: "float32x4",
              },
            ],

            arrayStride: 32,
            stepMode: "vertex",
          },
        ];

        // 创建渲染管线
        const pipelineDescriptor = {
          vertex: {
            module: shaderModule,
            entryPoint: "vertexMain",
            buffers: vertexBuffers,
          },
          fragment: {
            module: shaderModule,
            entryPoint: "fragmentMain",
            targets: [
              {
                format: navigator.gpu.getPreferredCanvasFormat(),
              },
            ],
          },
          primitive: {
            topology: "triangle-list",
          },
          layout: "auto",
        };

        //. 编码渲染命令

        const renderPipeline = device.createRenderPipeline(pipelineDescriptor); // 创建渲染管线
        const commandEncoder = device.createCommandEncoder(); // 创建命令编码器

        const clearColor = { r: 0.0, g: 0.5, b: 1.0, a: 1.0 };

        const renderPassDescriptor = {
          colorAttachments: [
            {
              clearValue: clearColor,
              loadOp: "clear",
              storeOp: "store",
              view: context.getCurrentTexture().createView(),
            },
          ],
        };

        const passEncoder =
          commandEncoder.beginRenderPass(renderPassDescriptor);
        passEncoder.setPipeline(renderPipeline);
        passEncoder.setVertexBuffer(0, vertexBuffer);
        passEncoder.draw(3);
        passEncoder.end();
        device.queue.submit([commandEncoder.finish()]);
      }
      main();
    </script>
  </body>
</html>
